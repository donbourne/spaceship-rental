quarkus.langchain4j.chat-model.provider=ollama
# quarkus.langchain4j.chat-model.provider=openai

langchain4j-ollama-dev-service.ollama.host=localhost
langchain4j-ollama-dev-service.ollama.port=11434
langchain4j-ollama-dev-service.ollama.endpoint=http://${langchain4j-ollama-dev-service.ollama.host}:${langchain4j-ollama-dev-service.ollama.port}
quarkus.langchain4j.ollama.chat-model.model-id=llama3.2
quarkus.langchain4j.ollama.chat-model.temperature=0.0
quarkus.langchain4j.ollama.timeout=60s

# quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
# quarkus.langchain4j.openai.chat-model.model-name=gpt-4o
# quarkus.langchain4j.openai.chat-model.log-requests=true
# quarkus.langchain4j.openai.chat-model.log-responses=true

quarkus.langchain4j.easy-rag.path=src/main/resources/rag/
quarkus.langchain4j.easy-rag.max-results=2
quarkus.langchain4j.easy-rag.reuse-embeddings.enabled=true
